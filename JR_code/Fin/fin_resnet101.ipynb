{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fin_resnet101.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brBeR3DCMIFS",
        "colab_type": "text"
      },
      "source": [
        "˙ 기존 resnet50이 정확도가 자꾸 80% 언저리, resnet50이 원래 다른 모델보다 정확도가 20-30% 낮다는 것을 감안, resnet100 한번 try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ossBf4X0L8pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDhHVFVaMrgQ",
        "colab_type": "code",
        "outputId": "0a582592-29d4-4cc8-9d83-2f142526d47c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 1. 필요 모듈 import\n",
        "import tensorflow as tf\n",
        "from keras.applications import ResNet101\n",
        "from keras.layers import Dense, Input, Activation\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import os, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMxBLqeFMxbI",
        "colab_type": "code",
        "outputId": "14614414-a824-4fd9-8ab1-fa1b7efb8980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 2. npy 데이터를 불러와서 모델 학습\n",
        "X_train, X_test, y_train, y_test = np.load(\"/content/drive/My Drive/fin.npy\", allow_pickle=True)\n",
        "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')  \n",
        "print(f'X_test: {X_test.shape}, y_test: {y_test.shape}') "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (28810, 64, 64, 3), y_train: (28810, 5)\n",
            "X_test: (7203, 64, 64, 3), y_test: (7203, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OvZhHRvM8Q0",
        "colab_type": "code",
        "outputId": "d8c18051-60ab-436d-bc83-8a41674237c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 모델 생성\n",
        "model = ResNet101(input_shape=(64, 64, 3), include_top=True, weights=None, pooling='max')  \n",
        "x = model.output\n",
        "x = Dense(1024, name='fully', init='uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dense(512, init='normal')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dense(256, init='normal')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dense(5, activation='softmax')(x)\n",
        "model = Model(model.input, x)\n",
        "model.summary()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1024, name=\"fully\", kernel_initializer=\"uniform\")`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, kernel_initializer=\"normal\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, kernel_initializer=\"normal\")`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 32, 32, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 16, 16, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 16, 16, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 16, 16, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 16, 16, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 16, 16, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 16, 16, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 16, 16, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 16, 16, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 16, 16, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 16, 16, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 16, 16, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 16, 16, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 16, 16, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 8, 8, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 8, 8, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 8, 8, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 8, 8, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 8, 8, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 8, 8, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 8, 8, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 8, 8, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 8, 8, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 8, 8, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 8, 8, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 8, 8, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 8, 8, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 4, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 4, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 4, 4, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 4, 4, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 4, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 4, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 4, 4, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 4, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 4, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 4, 4, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 4, 4, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 4, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 4, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 4, 4, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 4, 4, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 4, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 4, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 4, 4, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 4, 4, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 4, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 4, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 4, 4, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 4, 4, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 4, 4, 256)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_relu (Activation (None, 4, 4, 256)    0           conv4_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_add (Add)          (None, 4, 4, 1024)   0           conv4_block6_out[0][0]           \n",
            "                                                                 conv4_block7_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_out (Activation)   (None, 4, 4, 1024)   0           conv4_block7_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 4, 4, 256)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_relu (Activation (None, 4, 4, 256)    0           conv4_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_add (Add)          (None, 4, 4, 1024)   0           conv4_block7_out[0][0]           \n",
            "                                                                 conv4_block8_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_out (Activation)   (None, 4, 4, 1024)   0           conv4_block8_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 4, 4, 256)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_relu (Activation (None, 4, 4, 256)    0           conv4_block9_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block9_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block9_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_add (Add)          (None, 4, 4, 1024)   0           conv4_block8_out[0][0]           \n",
            "                                                                 conv4_block9_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_out (Activation)   (None, 4, 4, 1024)   0           conv4_block9_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block9_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block10_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block10_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block10_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_add (Add)         (None, 4, 4, 1024)   0           conv4_block9_out[0][0]           \n",
            "                                                                 conv4_block10_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_out (Activation)  (None, 4, 4, 1024)   0           conv4_block10_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block10_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block11_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block11_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block11_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_add (Add)         (None, 4, 4, 1024)   0           conv4_block10_out[0][0]          \n",
            "                                                                 conv4_block11_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_out (Activation)  (None, 4, 4, 1024)   0           conv4_block11_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block11_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block12_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block12_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block12_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_add (Add)         (None, 4, 4, 1024)   0           conv4_block11_out[0][0]          \n",
            "                                                                 conv4_block12_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_out (Activation)  (None, 4, 4, 1024)   0           conv4_block12_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block12_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block13_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block13_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block13_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_add (Add)         (None, 4, 4, 1024)   0           conv4_block12_out[0][0]          \n",
            "                                                                 conv4_block13_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_out (Activation)  (None, 4, 4, 1024)   0           conv4_block13_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block13_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block14_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block14_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block14_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_add (Add)         (None, 4, 4, 1024)   0           conv4_block13_out[0][0]          \n",
            "                                                                 conv4_block14_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_out (Activation)  (None, 4, 4, 1024)   0           conv4_block14_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block14_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block15_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block15_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block15_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_add (Add)         (None, 4, 4, 1024)   0           conv4_block14_out[0][0]          \n",
            "                                                                 conv4_block15_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_out (Activation)  (None, 4, 4, 1024)   0           conv4_block15_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block15_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block16_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block16_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block16_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_add (Add)         (None, 4, 4, 1024)   0           conv4_block15_out[0][0]          \n",
            "                                                                 conv4_block16_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_out (Activation)  (None, 4, 4, 1024)   0           conv4_block16_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block16_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block17_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block17_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block17_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_add (Add)         (None, 4, 4, 1024)   0           conv4_block16_out[0][0]          \n",
            "                                                                 conv4_block17_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_out (Activation)  (None, 4, 4, 1024)   0           conv4_block17_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block17_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block18_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block18_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block18_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_add (Add)         (None, 4, 4, 1024)   0           conv4_block17_out[0][0]          \n",
            "                                                                 conv4_block18_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_out (Activation)  (None, 4, 4, 1024)   0           conv4_block18_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block18_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block19_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block19_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block19_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_add (Add)         (None, 4, 4, 1024)   0           conv4_block18_out[0][0]          \n",
            "                                                                 conv4_block19_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_out (Activation)  (None, 4, 4, 1024)   0           conv4_block19_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block19_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block20_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block20_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block20_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_add (Add)         (None, 4, 4, 1024)   0           conv4_block19_out[0][0]          \n",
            "                                                                 conv4_block20_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_out (Activation)  (None, 4, 4, 1024)   0           conv4_block20_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block20_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block21_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block21_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block21_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_add (Add)         (None, 4, 4, 1024)   0           conv4_block20_out[0][0]          \n",
            "                                                                 conv4_block21_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_out (Activation)  (None, 4, 4, 1024)   0           conv4_block21_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block21_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block22_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block22_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block22_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_add (Add)         (None, 4, 4, 1024)   0           conv4_block21_out[0][0]          \n",
            "                                                                 conv4_block22_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_out (Activation)  (None, 4, 4, 1024)   0           conv4_block22_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 4, 4, 256)    262400      conv4_block22_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 4, 4, 256)    590080      conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block23_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block23_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_bn (BatchNormal (None, 4, 4, 1024)   4096        conv4_block23_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_add (Add)         (None, 4, 4, 1024)   0           conv4_block22_out[0][0]          \n",
            "                                                                 conv4_block23_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_out (Activation)  (None, 4, 4, 1024)   0           conv4_block23_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524800      conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 2, 2, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 2, 2, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 2, 2, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 2, 2, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "probs (Dense)                   (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fully (Dense)                   (None, 1024)         1025024     probs[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 1024)         4096        fully[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1024)         0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          524800      activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 512)          0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          131328      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 256)          1024        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 256)          0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 5)            1285        activation_3[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 46,396,781\n",
            "Trainable params: 46,287,853\n",
            "Non-trainable params: 108,928\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lho2rjJYTa1G",
        "colab_type": "code",
        "outputId": "66b0daf0-917f-4df1-f1fc-2a7dbb6836a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "# 4. 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.7, clipvalue=0.5), metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErMNAgNpu4H4",
        "colab_type": "code",
        "outputId": "dbab23e7-8eb5-4bd0-96de-d6893900ef92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "# 5. 모델 학습\n",
        "model_dir = \"./model\"\n",
        "if not os.path.exists(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "model_path = model_dir + '/test.model'\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "hist = model.fit(X_train, y_train, epochs=100, batch_size=100, callbacks=[checkpoint, early_stopping], validation_split=0.2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 23048 samples, validate on 5762 samples\n",
            "Epoch 1/100\n",
            "23048/23048 [==============================] - 111s 5ms/step - loss: 1.0983 - acc: 0.5609 - val_loss: 1.1260 - val_acc: 0.5644\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.12604, saving model to ./model/test.model\n",
            "Epoch 2/100\n",
            "23048/23048 [==============================] - 63s 3ms/step - loss: 0.5775 - acc: 0.7884 - val_loss: 0.9793 - val_acc: 0.5951\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.12604 to 0.97928, saving model to ./model/test.model\n",
            "Epoch 3/100\n",
            "23048/23048 [==============================] - 63s 3ms/step - loss: 0.4245 - acc: 0.8437 - val_loss: 0.9680 - val_acc: 0.6946\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.97928 to 0.96797, saving model to ./model/test.model\n",
            "Epoch 4/100\n",
            "23048/23048 [==============================] - 63s 3ms/step - loss: 0.3231 - acc: 0.8830 - val_loss: 0.8230 - val_acc: 0.7447\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.96797 to 0.82296, saving model to ./model/test.model\n",
            "Epoch 5/100\n",
            "23048/23048 [==============================] - 63s 3ms/step - loss: 0.2591 - acc: 0.9047 - val_loss: 0.3727 - val_acc: 0.8733\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.82296 to 0.37272, saving model to ./model/test.model\n",
            "Epoch 6/100\n",
            "23048/23048 [==============================] - 63s 3ms/step - loss: 0.2138 - acc: 0.9232 - val_loss: 1.0449 - val_acc: 0.6725\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.37272\n",
            "Epoch 7/100\n",
            "23048/23048 [==============================] - 63s 3ms/step - loss: 0.1675 - acc: 0.9393 - val_loss: 0.8207 - val_acc: 0.7624\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.37272\n",
            "Epoch 8/100\n",
            "23048/23048 [==============================] - 63s 3ms/step - loss: 0.1640 - acc: 0.9433 - val_loss: 0.8752 - val_acc: 0.7379\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.37272\n",
            "Epoch 9/100\n",
            "23048/23048 [==============================] - 63s 3ms/step - loss: 0.1403 - acc: 0.9527 - val_loss: 0.3897 - val_acc: 0.8652\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.37272\n",
            "Epoch 10/100\n",
            "23048/23048 [==============================] - 63s 3ms/step - loss: 0.1157 - acc: 0.9613 - val_loss: 0.6111 - val_acc: 0.8190\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.37272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UCT_FL0u9ey",
        "colab_type": "code",
        "outputId": "9a004e1a-ec8b-43eb-ea26-efa1a758758c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# loss 그래프\n",
        "train_loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "x = range(len(train_loss))\n",
        "plt.plot(x, train_loss, marker='.', color='red', label='Train loss')\n",
        "plt.plot(x, val_loss, marker='.', color='blue', label='Val loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss during epochs')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc0nOE4FzziU5TwTOOZfkPBE451yS+39CjYKCi2IxmAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvQLCrsGvF2u",
        "colab_type": "code",
        "outputId": "05ce66de-1aca-4c5c-913d-7b552d172cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# acc 그래프\n",
        "train_acc = hist.history['acc']\n",
        "val_acc = hist.history['val_acc']\n",
        "\n",
        "plt.plot(x, train_acc, marker='.', c='red', label='Train Acc.')\n",
        "plt.plot(x, val_acc, marker='.', c='blue', label='Val Acc.')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy during epochs')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8gThnHOuRP8PYtvwbf3lJlAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsLbjx6FvLGc",
        "colab_type": "code",
        "outputId": "d957308a-4f8a-498d-cbf8-3cd0c3e73328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Test set으로 모델 평가\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Training loss:', score[0])\n",
        "print('Training accuracy: ', score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.616604902944589\n",
            "Training accuracy:  0.8152158822712758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2DFVncJvOKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 저장하기\n",
        "from keras.models import load_model\n",
        "model.save('fin_resnet101.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwooB5m6vSHJ",
        "colab_type": "code",
        "outputId": "5a1fa221-2626-4191-8344-610701b0b091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "test_true = np.argmax(y_test, axis=1)\n",
        "print(test_true)\n",
        "test_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "print(test_pred)\n",
        "\n",
        "cm = confusion_matrix(test_true, test_pred)\n",
        "print(cm)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 1 2 ... 2 1 0]\n",
            "[3 1 2 ... 2 1 0]\n",
            "[[ 968  153  183   81   55]\n",
            " [   0 1335   13    4   25]\n",
            " [   2  152 1097  143    1]\n",
            " [  65   76  296 1048   33]\n",
            " [   6   16   25    2 1424]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYm10BKTvXXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "84e67b5e-a628-41ae-be47-e6d4ef940660"
      },
      "source": [
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(test_true, test_pred, target_names=os.listdir('/content/drive/My Drive/Final'))\n",
        "print(report)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       nevus       0.93      0.67      0.78      1440\n",
            "          df       0.77      0.97      0.86      1377\n",
            "      eschar       0.68      0.79      0.73      1395\n",
            "          vl       0.82      0.69      0.75      1518\n",
            "         mel       0.93      0.97      0.95      1473\n",
            "\n",
            "    accuracy                           0.82      7203\n",
            "   macro avg       0.83      0.82      0.81      7203\n",
            "weighted avg       0.83      0.82      0.81      7203\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL8ZHnFVo9DW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
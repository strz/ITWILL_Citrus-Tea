{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception_v3_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN9P2fKASj/Nz0uI7am44WH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/strz/ITWILL_Citrus-Tea/blob/master/Inception_v3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB4Q2KoU2t0L",
        "colab_type": "text"
      },
      "source": [
        "**파이썬 Inception_v3를 이용한 쯔쯔가무시 등 5종 분류 및 예측**\n",
        "\n",
        "2020.02.20 (목)\n",
        " - 각 클래스당 이미지를 2,000장 부풀려 클래스당 비율을 맞춤.<br>\n",
        " (xy_googlenet_1_save.npy: 2,000장 (224,224) 사용)\n",
        " - 모델은 Inception_v3의 pretrained model 사용.<br>\n",
        " (keras.applications.inception_v3에서 이미 학습된 가중치값을 가져와 학습, 속도가 훨씬 빠름)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SSPfpvx25C0",
        "colab_type": "text"
      },
      "source": [
        "**1. 버전 설정 및 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vn-tAZA23_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c010a090-7419-4dba-da90-bb5ade029613"
      },
      "source": [
        "# Tensorflow 사용버전 설정\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Tensorflow 버전과 GPU 사용 여부 확인\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name()) "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS03AR5W29ah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "e9f31678-52aa-4515-9fdb-9848239ded84"
      },
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkm-P2qF3ges",
        "colab_type": "text"
      },
      "source": [
        "**2. 클래스 및 모듈 import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwgqfQNa3gNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62df2e62-8e23-4fec-8cce-8e0ada68bfbf"
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Dropout, GlobalAveragePooling2D, Dense, AveragePooling2D, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "\n",
        "from keras.engine.saving import load_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6lhWcwS5CJU",
        "colab_type": "text"
      },
      "source": [
        "**3. dataset 불러오기 & 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQfMt6uP5Ej6",
        "colab_type": "text"
      },
      "source": [
        "(생략된 부분 - 이미지 부풀리는 과정)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJbLR5aY8et1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7283c37d-c50d-46a3-cc5b-eedb7c23d1eb"
      },
      "source": [
        "### np.save로 저장된 파일 불러오기\n",
        "X_train, X_test, y_train, y_test = np.load('./drive/My Drive/final_project/xy_googlenet_1_save.npy', allow_pickle=True)\n",
        "# xy_googlenet_1_save.npy = 2,000장씩 (224,224,3)\n",
        "\n",
        "# 정규화 시키기\n",
        "X_train = X_train.astype('float16') / 255\n",
        "X_test = X_test.astype('float16') / 255\n",
        "\n",
        "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')   # X_train: (9144, 224, 224, 3), y_train: (9144, 5)\n",
        "print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')   # X_test: (2287, 224, 224, 3), y_test: (2287, 5)\n",
        "\n",
        "print(f'X_train: {X_train[0]}, X_test: {X_test[0]}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (9144, 224, 224, 3), y_train: (9144, 5)\n",
            "X_test: (2287, 224, 224, 3), y_test: (2287, 5)\n",
            "X_train: [[[0.886  0.8115 0.745 ]\n",
            "  [0.9097 0.8354 0.7686]\n",
            "  [0.933  0.859  0.792 ]\n",
            "  ...\n",
            "  [0.8237 0.643  0.5527]\n",
            "  [0.8354 0.655  0.5605]\n",
            "  [0.8706 0.6904 0.596 ]]\n",
            "\n",
            " [[0.886  0.8115 0.745 ]\n",
            "  [0.9097 0.8354 0.7686]\n",
            "  [0.933  0.859  0.792 ]\n",
            "  ...\n",
            "  [0.8237 0.643  0.5527]\n",
            "  [0.8354 0.655  0.5605]\n",
            "  [0.8706 0.6904 0.596 ]]\n",
            "\n",
            " [[0.89   0.816  0.749 ]\n",
            "  [0.906  0.8315 0.7646]\n",
            "  [0.9214 0.847  0.7803]\n",
            "  ...\n",
            "  [0.8276 0.647  0.5566]\n",
            "  [0.8354 0.655  0.5605]\n",
            "  [0.8667 0.686  0.5923]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.9453 0.8784 0.816 ]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  ...\n",
            "  [0.89   0.784  0.702 ]\n",
            "  [0.8823 0.784  0.706 ]\n",
            "  [0.8706 0.7725 0.6943]]\n",
            "\n",
            " [[0.9414 0.8745 0.8115]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  ...\n",
            "  [0.894  0.788  0.706 ]\n",
            "  [0.8823 0.784  0.706 ]\n",
            "  [0.859  0.7607 0.682 ]]\n",
            "\n",
            " [[0.9414 0.8745 0.8115]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  [0.9414 0.8745 0.8115]\n",
            "  ...\n",
            "  [0.894  0.788  0.706 ]\n",
            "  [0.8823 0.784  0.706 ]\n",
            "  [0.859  0.7607 0.682 ]]], X_test: [[[0.7803 0.569  0.569 ]\n",
            "  [0.7764 0.565  0.565 ]\n",
            "  [0.7764 0.5566 0.5605]\n",
            "  ...\n",
            "  [0.855  0.6704 0.608 ]\n",
            "  [0.847  0.6626 0.6   ]\n",
            "  [0.8394 0.655  0.5923]]\n",
            "\n",
            " [[0.7803 0.569  0.569 ]\n",
            "  [0.7764 0.565  0.565 ]\n",
            "  [0.7764 0.5566 0.5605]\n",
            "  ...\n",
            "  [0.855  0.6704 0.608 ]\n",
            "  [0.847  0.6626 0.6   ]\n",
            "  [0.8394 0.655  0.5923]]\n",
            "\n",
            " [[0.7803 0.569  0.569 ]\n",
            "  [0.7764 0.565  0.565 ]\n",
            "  [0.7764 0.5566 0.5605]\n",
            "  ...\n",
            "  [0.855  0.6704 0.608 ]\n",
            "  [0.851  0.6665 0.604 ]\n",
            "  [0.847  0.6626 0.6   ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.8394 0.608  0.6157]\n",
            "  [0.8433 0.612  0.6196]\n",
            "  [0.847  0.6157 0.6235]\n",
            "  ...\n",
            "  [0.933  0.6743 0.682 ]\n",
            "  [0.933  0.682  0.686 ]\n",
            "  [0.9453 0.6943 0.698 ]]\n",
            "\n",
            " [[0.859  0.6274 0.6353]\n",
            "  [0.859  0.6274 0.6353]\n",
            "  [0.863  0.6313 0.639 ]\n",
            "  ...\n",
            "  [0.9453 0.686  0.702 ]\n",
            "  [0.9453 0.686  0.702 ]\n",
            "  [0.949  0.6904 0.706 ]]\n",
            "\n",
            " [[0.8706 0.639  0.647 ]\n",
            "  [0.8745 0.643  0.651 ]\n",
            "  [0.8784 0.647  0.655 ]\n",
            "  ...\n",
            "  [0.949  0.686  0.714 ]\n",
            "  [0.949  0.6904 0.706 ]\n",
            "  [0.9453 0.686  0.702 ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyH82ZrM81Iv",
        "colab_type": "text"
      },
      "source": [
        "**5. 신경망 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12Y7O4Kz80jG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e62927d6-3287-4f3a-f633-c4b11fc7f19d"
      },
      "source": [
        "# pre_trained model 불러오기\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = InceptionV3(include_top=False,\n",
        "                          weights='imagenet',\n",
        "                          input_shape=input_shape)\n",
        "x = base_model.output\n",
        "x = Dropout(0.5)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 요약\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 111, 111, 32) 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 111, 111, 32) 96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 111, 111, 32) 0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 109, 109, 32) 9216        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 109, 109, 32) 96          conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 109, 109, 32) 0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 109, 109, 64) 18432       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 109, 109, 64) 192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 109, 109, 64) 0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 54, 54, 80)   5120        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 54, 54, 80)   240         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 54, 54, 80)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 52, 52, 192)  138240      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 52, 52, 192)  576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 52, 52, 192)  0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 25, 25, 64)   192         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 25, 25, 64)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 25, 25, 96)   55296       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 25, 25, 48)   144         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 25, 25, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 25, 25, 48)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 25, 25, 96)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 25, 25, 64)   76800       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 25, 25, 96)   82944       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 25, 25, 64)   192         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 25, 25, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 25, 25, 96)   288         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 25, 25, 32)   96          conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 25, 25, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 25, 25, 64)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 25, 25, 96)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 25, 25, 32)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_100[0][0]             \n",
            "                                                                 activation_102[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "                                                                 activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 25, 25, 64)   192         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 25, 25, 64)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 25, 25, 96)   55296       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 25, 25, 48)   144         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 25, 25, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 25, 25, 48)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 25, 25, 96)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 25, 25, 64)   76800       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 25, 25, 96)   82944       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 25, 25, 64)   192         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 25, 25, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 25, 25, 96)   288         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 25, 25, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 25, 25, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 25, 25, 64)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 25, 25, 96)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 25, 25, 64)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_107[0][0]             \n",
            "                                                                 activation_109[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "                                                                 activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 25, 25, 64)   192         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 25, 25, 64)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 25, 25, 96)   55296       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 25, 25, 48)   144         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 25, 25, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 25, 25, 48)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 25, 25, 96)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 25, 25, 64)   76800       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 25, 25, 96)   82944       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 25, 25, 64)   192         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 25, 25, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 25, 25, 96)   288         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 25, 25, 64)   192         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 25, 25, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 25, 25, 64)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 25, 25, 96)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 25, 25, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_114[0][0]             \n",
            "                                                                 activation_116[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "                                                                 activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 25, 25, 64)   192         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 25, 25, 64)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 25, 25, 96)   55296       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 25, 25, 96)   288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 25, 25, 96)   0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 12, 12, 96)   82944       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 12, 12, 384)  1152        conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 12, 12, 96)   288         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 384)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 96)   0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_121[0][0]             \n",
            "                                                                 activation_124[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 12, 12, 128)  114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 12, 12, 128)  384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 12, 12, 128)  114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 12, 12, 128)  384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 12, 12, 128)  384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 128)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 12, 12, 128)  114688      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 12, 12, 128)  114688      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 12, 12, 128)  384         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 12, 12, 128)  384         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 128)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 128)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 12, 12, 192)  172032      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 12, 12, 192)  172032      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 12, 12, 192)  576         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 12, 12, 192)  576         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 12, 12, 192)  576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 12, 12, 192)  576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 192)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 192)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 192)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 192)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_125[0][0]             \n",
            "                                                                 activation_128[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "                                                                 activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 12, 12, 160)  480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 12, 12, 160)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 12, 12, 160)  179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 12, 12, 160)  480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 12, 12, 160)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 12, 12, 160)  179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 12, 12, 160)  480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 12, 12, 160)  480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 160)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 12, 12, 160)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 12, 12, 160)  179200      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 12, 12, 160)  179200      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 12, 12, 160)  480         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 12, 12, 160)  480         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 160)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 12, 12, 160)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 12, 12, 192)  215040      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 12, 12, 192)  215040      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 12, 12, 192)  576         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 12, 12, 192)  576         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 192)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 12, 12, 192)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 12, 12, 192)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_135[0][0]             \n",
            "                                                                 activation_138[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "                                                                 activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 12, 12, 160)  480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 12, 12, 160)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 12, 12, 160)  179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 12, 12, 160)  179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 12, 12, 160)  480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 12, 12, 160)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 12, 12, 160)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 12, 12, 160)  179200      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 12, 12, 160)  179200      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 12, 12, 160)  480         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 12, 12, 160)  480         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 12, 12, 160)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 12, 12, 160)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 12, 12, 192)  215040      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 12, 12, 192)  215040      activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 12, 12, 192)  576         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 12, 12, 192)  576         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 12, 12, 192)  576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 12, 12, 192)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 12, 12, 192)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 12, 12, 192)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_145[0][0]             \n",
            "                                                                 activation_148[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "                                                                 activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 12, 12, 192)  576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 12, 12, 192)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 12, 12, 192)  258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 12, 12, 192)  576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 12, 12, 192)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 12, 12, 192)  258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 12, 12, 192)  576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 12, 12, 192)  576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 12, 12, 192)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 12, 12, 192)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 12, 12, 192)  258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 12, 12, 192)  258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 12, 12, 192)  576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 12, 12, 192)  576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 12, 12, 192)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 12, 12, 192)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 12, 12, 192)  258048      activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 12, 12, 192)  258048      activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 12, 12, 192)  576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 12, 12, 192)  576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 12, 12, 192)  576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 12, 12, 192)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 12, 12, 192)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 12, 12, 192)  0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_155[0][0]             \n",
            "                                                                 activation_158[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "                                                                 activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 12, 12, 192)  576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 12, 12, 192)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 12, 12, 192)  258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 12, 12, 192)  576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 12, 12, 192)  0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 12, 12, 192)  258048      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 12, 12, 192)  576         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 12, 12, 192)  576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 12, 12, 192)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 12, 12, 192)  0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 5, 5, 320)    552960      activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 5, 5, 192)    331776      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 5, 5, 320)    960         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 5, 5, 192)    576         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 5, 5, 320)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 5, 5, 192)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_166[0][0]             \n",
            "                                                                 activation_170[0][0]             \n",
            "                                                                 max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 5, 5, 448)    1344        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 5, 5, 448)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 5, 5, 384)    1548288     activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 5, 5, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 5, 5, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 5, 5, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 5, 5, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 5, 5, 384)    442368      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 5, 5, 384)    442368      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 5, 5, 384)    442368      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 5, 5, 384)    442368      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 5, 5, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 5, 5, 384)    1152        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 5, 5, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 5, 5, 384)    1152        conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 5, 5, 320)    960         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 5, 5, 384)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 5, 5, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 5, 5, 384)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 5, 5, 384)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 5, 5, 192)    576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 5, 5, 320)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_173[0][0]             \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 5, 5, 768)    0           activation_177[0][0]             \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 5, 5, 192)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_171[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 5, 5, 448)    1344        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 5, 5, 448)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 5, 5, 384)    1548288     activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 5, 5, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 5, 5, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 5, 5, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 5, 5, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 5, 5, 384)    442368      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 5, 5, 384)    442368      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 5, 5, 384)    442368      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 5, 5, 384)    442368      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 5, 5, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 5, 5, 384)    1152        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 5, 5, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 5, 5, 384)    1152        conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 5, 5, 320)    960         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 5, 5, 384)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 5, 5, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 5, 5, 384)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 5, 5, 384)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 5, 5, 192)    576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 5, 5, 320)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_182[0][0]             \n",
            "                                                                 activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_186[0][0]             \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 5, 5, 192)    0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_180[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 5, 5, 2048)   0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 2048)         0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 512)          524800      dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 512)          2048        dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 5)            2565        batch_normalization_190[0][0]    \n",
            "==================================================================================================\n",
            "Total params: 24,430,373\n",
            "Trainable params: 24,394,917\n",
            "Non-trainable params: 35,456\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s96E7x6Fcpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "89efd7ce-c3ad-4e66-9617-076f05b94d28"
      },
      "source": [
        "# 컴파일\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK01JUuH9A7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ce815ac-a163-49b7-dc28-026fee0ebebe"
      },
      "source": [
        "# 신경망 모델의 성능 향상이 없는 경우 중간에 epoch을 빨리 중지시키기 위해서\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                            verbose=1,\n",
        "                            patience=10)\n",
        "\n",
        "# 신경망 학습모델 파일로 저장\n",
        "model_dir = \"./drive/My Drive/final_project/\"\n",
        "if not os.path.exists(model_dir):  # model_dir이 없을 경우 폴더 생성\n",
        "    os.mkdir(model_dir)\n",
        "\n",
        "model_path = model_dir + '/Inception_v3_2.model'\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# 신경망 학습\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,     # 에폭만큼 파라미터 업데이트\n",
        "                    batch_size=200,  # 전체갯수를 batch_size로 나눈 만큼 반복\n",
        "                    callbacks=[checkpoint, early_stop],\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 7315 samples, validate on 1829 samples\n",
            "Epoch 1/100\n",
            "7315/7315 [==============================] - 67s 9ms/step - loss: 0.4817 - acc: 0.8185 - val_loss: 0.9550 - val_acc: 0.7447\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.95496, saving model to ./drive/My Drive/final_project//Inception_v3_2.model\n",
            "Epoch 2/100\n",
            "7315/7315 [==============================] - 43s 6ms/step - loss: 0.2646 - acc: 0.8962 - val_loss: 0.8957 - val_acc: 0.7419\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.95496 to 0.89571, saving model to ./drive/My Drive/final_project//Inception_v3_2.model\n",
            "Epoch 3/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.2225 - acc: 0.9151 - val_loss: 0.3476 - val_acc: 0.8704\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.89571 to 0.34762, saving model to ./drive/My Drive/final_project//Inception_v3_2.model\n",
            "Epoch 4/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.1450 - acc: 0.9459 - val_loss: 0.7004 - val_acc: 0.7933\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.34762\n",
            "Epoch 5/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.0979 - acc: 0.9639 - val_loss: 0.3845 - val_acc: 0.8770\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.34762\n",
            "Epoch 6/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.0930 - acc: 0.9669 - val_loss: 0.6481 - val_acc: 0.8136\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.34762\n",
            "Epoch 7/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.1017 - acc: 0.9642 - val_loss: 0.9999 - val_acc: 0.7512\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.34762\n",
            "Epoch 8/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.0654 - acc: 0.9762 - val_loss: 1.2446 - val_acc: 0.7676\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.34762\n",
            "Epoch 9/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.0992 - acc: 0.9639 - val_loss: 0.7476 - val_acc: 0.7802\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.34762\n",
            "Epoch 10/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.0803 - acc: 0.9714 - val_loss: 2.3991 - val_acc: 0.6419\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.34762\n",
            "Epoch 11/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.3702 - acc: 0.8679 - val_loss: 4.4266 - val_acc: 0.4002\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.34762\n",
            "Epoch 12/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.1624 - acc: 0.9404 - val_loss: 1.1992 - val_acc: 0.7895\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.34762\n",
            "Epoch 13/100\n",
            "7315/7315 [==============================] - 42s 6ms/step - loss: 0.0797 - acc: 0.9724 - val_loss: 0.9476 - val_acc: 0.7966\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.34762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wguizP5r9kwK",
        "colab_type": "text"
      },
      "source": [
        "**6. 신경망 학습 및 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-O-bPDK9klL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "de419e87-ff06-4193-b8da-796709795c3d"
      },
      "source": [
        "# 테스트 데이터를 사용해서 신경망 모델을 평가\n",
        "# 테스트 데이터의 Loss, Accuracy\n",
        "eval = model.evaluate(X_test, y_test)\n",
        "print(f'Test loss: {eval[0]}, accuracy: {eval[1]}')\n",
        "### 1\n",
        "# Test loss: 0.922806359721617, accuracy: 0.8117209708250093\n",
        "### 2\n",
        "# Test loss: 0.5639182739725371, accuracy: 0.86226497597709\n",
        "# loss: 0.0298 - acc: 0.9891 - val_loss: 0.6317 - val_acc: 0.8529\n",
        "\n",
        "### 3\n",
        "# Test loss: 0.9771581690646073, accuracy: 0.7901180587484162"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2287/2287 [==============================] - 5s 2ms/step\n",
            "Test loss: 0.9771581690646073, accuracy: 0.7901180587484162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8eynDSC3pNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "9deef96b-d2da-4224-b43d-c2ab0fe719a4"
      },
      "source": [
        "# 학습 데이터와 테스트 데이터의 Loss 그래프\n",
        "train_loss = history.history['loss']  # history dictionary에 저장된 'loss' 키를 갖는 value들을 가져옴\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "x = range(len(train_loss))\n",
        "plt.plot(x, train_loss, marker='.', color='red', label='Train loss')\n",
        "plt.plot(x, val_loss, marker='.', color='blue', label='Val loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5FFM8EREHsUET0TkUUzwREQe9f8BsMvBjvhhXNUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd3GQ4aN3s6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a28e575a-7e00-4cfc-aa7d-06dac77e55a8"
      },
      "source": [
        "# 학습 데이터, 테스트 데이터의 정확도 그래프\n",
        "train_accuracy = history.history['acc']\n",
        "val_accuracy = history.history['val_acc']\n",
        "\n",
        "x = range(len(train_accuracy))\n",
        "plt.plot(x, train_accuracy, marker='.', color='red', label='Train loss')\n",
        "plt.plot(x, val_accuracy, marker='.', color='blue', label='Val loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEJCAYAAACZjSCSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZxU4L_G4N96",
        "colab_type": "text"
      },
      "source": [
        "**7. Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc26dbx431dU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "95c0cb15-e460-455f-9682-fda5a0350e48"
      },
      "source": [
        "# # 저장한 학습모델 불러옴.\n",
        "# model = load_model('./model/Inception_v3_2.model')\n",
        "\n",
        "categories = [\"df\", \"mel\", \"nv\", \"tsu\", \"vl\"]\n",
        "\n",
        "# confusion matrix & classification report\n",
        "print(y_test)\n",
        "\n",
        "y_true = np.argmax(y_test, axis=1)   # 행 중 가장 큰값의 idx\n",
        "# (one-hot-encoding 되어있으므로 1로 표시된 값을 행에서 가장 큰값으로 출력하여 array로 만듦)\n",
        "print(y_true)\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "print(y_pred)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n",
        "# 세로가 실제클래스, 가로가 예측클래스\n",
        "## 1 \n",
        "# [[ 420  334   44   33    1]\n",
        "#  [   1  860   68    1    0]\n",
        "#  [   1  312  595    2    3]\n",
        "#  [   1   20    2 1018    3]\n",
        "#  [   0   13   18    4  819]]\n",
        "\n",
        "### 2\n",
        "# [[412   5  23   3   2]\n",
        "#  [  4 380  58   9   0]\n",
        "#  [  1  40 393   4   0]\n",
        "#  [  0   0   0 536   0]\n",
        "#  [  0   5   2  26 384]]\n",
        "\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=categories)\n",
        "print(report)\n",
        "## 1\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#           df       0.99      0.50      0.67       832\n",
        "#          mel       0.56      0.92      0.70       930\n",
        "#           nv       0.82      0.65      0.73       913\n",
        "#          tsu       0.96      0.98      0.97      1044\n",
        "#           vl       0.99      0.96      0.97       854\n",
        "\n",
        "#     accuracy                           0.81      4573\n",
        "#    macro avg       0.86      0.80      0.81      4573\n",
        "# weighted avg       0.86      0.81      0.81      4573\n",
        "\n",
        "### 2\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#           df       0.99      0.93      0.96       445\n",
        "#          mel       0.88      0.84      0.86       451\n",
        "#           nv       0.83      0.90      0.86       438\n",
        "#          tsu       0.93      1.00      0.96       536\n",
        "#           vl       0.99      0.92      0.96       417\n",
        "\n",
        "#     accuracy                           0.92      2287\n",
        "#    macro avg       0.92      0.92      0.92      2287\n",
        "# weighted avg       0.92      0.92      0.92      2287\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " ...\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]]\n",
            "[0 3 3 ... 1 1 2]\n",
            "[0 3 3 ... 2 2 2]\n",
            "[[226   2 206  10   1]\n",
            " [  4 276 155  16   0]\n",
            " [  1  37 395   5   0]\n",
            " [  7   0   4 524   1]\n",
            " [  0   0   8  23 386]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          df       0.95      0.51      0.66       445\n",
            "         mel       0.88      0.61      0.72       451\n",
            "          nv       0.51      0.90      0.66       438\n",
            "         tsu       0.91      0.98      0.94       536\n",
            "          vl       0.99      0.93      0.96       417\n",
            "\n",
            "    accuracy                           0.79      2287\n",
            "   macro avg       0.85      0.78      0.79      2287\n",
            "weighted avg       0.85      0.79      0.79      2287\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
import os

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.model_selection import train_test_split
from tensorflow.keras import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense
from tensorflow.keras.preprocessing.image import img_to_array, ImageDataGenerator, load_img
from tensorflow.keras.utils import to_categorical



def file_to_array(path, n=7060):
    file_list = os.listdir(path)
    print('file_list{}'.format(file_list))
    X = []
    for name in file_list[:n]:
        im = Image.open(path + name)
        im = img_to_array(im)   
        X.append(im)
    X = np.array(X)
    return X


def creat_label(path):
    """ 폴더 안에 있는 파일이름으로 one-hot-encoding """
    file_list = os.listdir(path)
    print(file_list)
    y = []
    for name in file_list:
        if 'tsutsu' in name:
            tsutsu_encoding = np.array([1, 0])  
            y.append(tsutsu_encoding)
        elif 'eschar' in name:
            eschar_ecoding = np.array([0, 1])
            y.append(eschar_ecoding)
    return np.array(y)  


if __name__ == '__main__':
    train_datagen = ImageDataGenerator(rescale=1. / 255 ,
                                       rotation_range=30 ,  
                                       width_shift_range=0.1 , 
                                       height_shift_range=0.1 , 
                                       brightness_range=[0.2 , 0.7],
                                       shear_range=0.7 ,  
                                       zoom_range=[0.9 , 1.1] ,
                                       horizontal_flip=True ,  
                                       vertical_flip=True ,
                                       fill_mode='nearest')
    test_datagen = ImageDataGenerator(rescale=1 / 255)  

    path = 'C:/dev/refined_images/eschar/'

    file_list = os.listdir(path)
    print('file_list: {}'.format(file_list))
    print(len(file_list))

    save_to_dir = 'C:/dev/refined_images/eschar/'

    for name in file_list:
        img = load_img(path + name)
        x = img_to_array(img)
        x = x.reshape((1,) + x.shape)  
        i = 0
        for _ in train_datagen.flow(x, save_to_dir=save_to_dir,
                                    save_prefix=name.split('.')[0]+'_gen', save_format='jpg'):
            i += 1
            if i >= 10:
                break


    np.save('C:/dev/refined_images/x_save', x)
    x_save_load = np.load('C:/dev/refined_images/x_save.npy')
    print(x_save_load)

    path = 'C:/dev/refined_images/eschar/'
    X = file_to_array(path)
    print(X[0:2])
    print(f'X.shape: {np.shape(X)}') 
    print(type(X))
    print(X.shape)

    path = 'C:/dev/refined_images/eschar/'
    y = creat_label(path)
    # print(y)
    print(type(y))
    print(y.shape)

    np.random.seed(210)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    xy = (X_train, X_test, y_train, y_test)
    np.save('./xy_save.npy', xy)   # x_save.npy
    X_train, X_test, y_train, y_test = np.load('./xy_save.npy', allow_pickle=True)
    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

    y_train = to_categorical(y_train, 2, dtype='float32')
    y_test = to_categorical(y_test, 2, dtype='float32')
    print(y_train[:1], y_train.shape)
    print(y_test[:1])

    X_train = X_train / 255
    X_test = X_test / 255

    print(f'X_train: {X_train.shape}, y_train: {y_train.shape}') 
    print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')  

    print(f'X_train: {X_train[0:2]}, X_test: {X_test[0:2]}')

    model = Sequential()

    model.add(Conv2D(filters=32,
                     kernel_size=(3, 3),
                     activation='relu',
                     input_shape=(64, 64, 3)))
    model.add(Conv2D(filters=64,
                     kernel_size=(3, 3),
                     activation='relu'))
    model.add(MaxPool2D(pool_size=2))
    model.add(Dropout(rate=0.25))
    model.add(Flatten())
    model.add(Dense(units=128, activation='relu'))
    model.add(Dropout(rate=0.5))
    model.add(Dense(units=2, activation='softmax'))

    model.summary()

    model.compile(loss='binary_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])

    early_stop = EarlyStopping(monitor='val_loss',
                               patience=10,
                               verbose=1)

    history = model.fit(X_train, y_train,
                        batch_size=100,
                        epochs=50,
                        verbose=1,
                        callbacks=[early_stop],
                        validation_data=(X_test, y_test))

    eval = model.evaluate(X_test, y_test)
    print(f'Test loss: {eval[0]}, accuracy: {eval[1]}')

    train_loss = history.history['loss']
    test_loss = history.history['val_loss']

    train_acc = history.history['accuracy']
    test_acc = history.history['val_accuracy']

    x = range(len(train_loss))
    plt.plot(x, train_loss, marker='.', color='red', label='Train loss')
    plt.plot(x, test_loss, marker='.', color='blue', label='Test loss')
    plt.legend()
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.title('Loss during epochs')
    plt.show()

    plt.plot(x, train_acc, marker='.', c='red', label='Train Acc.')
    plt.plot(x, test_acc, marker='.', c='blue', label='Test Acc.')
    plt.legend()
    plt.xlabel('epoch')
    plt.ylabel('accuracy')
    plt.title('Accuracy during epochs')
    plt.show()
